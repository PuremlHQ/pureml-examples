{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pureml\n",
    "\n",
    "pureml.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pureml_evaluate \n",
    "\n",
    "pureml_evaluate.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"CreditDefender Dataset Test\"\n",
    "model_name = \"CreditDefender Model2 Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the required files\n",
    "import pureml\n",
    "from pureml.decorators import load_data,transformer,dataset,model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "import random\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "rand_seed = 1234\n",
    "np.random.seed(rand_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pureml.decorators import load_data\n",
    "\n",
    "@load_data()\n",
    "def load():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@load_data()\n",
    "def load_dataset():\n",
    "    df = pd.read_csv('default of credit card clients.csv', header=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@transformer()\n",
    "def remove_columns(df):\n",
    "    return df.drop(['ID'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@transformer()\n",
    "def rename_columns(df):\n",
    "    return df.rename(columns={\"PAY_0\": \"PAY_1\",\"default payment next month\":\"default\", \"SEX\":\"sex\"})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@transformer()\n",
    "def dataset_imbalances(df):\n",
    "    categorical_features = [\"sex\", \"EDUCATION\", \"MARRIAGE\"]\n",
    "\n",
    "    for col_name in categorical_features:\n",
    "        df[col_name] = df[col_name].astype(\"category\")\n",
    "\n",
    "    Y, A = df.loc[:, \"default\"], df.loc[:, \"sex\"]\n",
    "    X = pd.get_dummies(df.drop(columns=[\"default\", \"sex\"]))\n",
    "\n",
    "\n",
    "    A_str = A.map({1: \"male\", 2: \"female\"})\n",
    "\n",
    "    A_str.value_counts(normalize=True)\n",
    "    Y.value_counts(normalize=True)\n",
    "    \n",
    "    # Generate \"Interest\" column as a DataFrame\n",
    "    interest_values = np.random.normal(loc=2 * Y, scale=A)\n",
    "    interest_column = pd.DataFrame(interest_values, columns=[\"Interest\"])\n",
    "\n",
    "    # Concatenate \"Interest\" column with X DataFrame\n",
    "    X = pd.concat([X, interest_column], axis=1)\n",
    "\n",
    "    return {'X':X,'Y':Y,'A_str':A_str}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@transformer()\n",
    "def resample_training_data(X_train, Y_train, A_train):\n",
    "   \n",
    "    negative_ids = Y_train[Y_train == 0].index\n",
    "    positive_ids = Y_train[Y_train == 1].index\n",
    "    balanced_ids = positive_ids.union(\n",
    "        np.random.choice(a=negative_ids, size=len(positive_ids)))\n",
    "\n",
    "    X_train = X_train.loc[balanced_ids, :]\n",
    "    Y_train = Y_train.loc[balanced_ids]\n",
    "    A_train = A_train.loc[balanced_ids]\n",
    "    return  {\"X_train\": X_train, \"Y_train\":Y_train, \"A_train\": A_train}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@transformer()\n",
    "def add_new_column(sensitive_features):\n",
    "    values = ['Indian', 'African', 'American']\n",
    "\n",
    "    list_length = sensitive_features.shape[0]\n",
    "    full_list = values * (list_length // len(values))\n",
    "    full_list += values[:list_length % len(values)]\n",
    "    random.shuffle(full_list)\n",
    "\n",
    "    full_list = np.array(full_list)\n",
    "\n",
    "    s_feat = pd.concat([sensitive_features.reset_index(drop=True), pd.DataFrame(full_list, columns=['race'])], axis=1)\n",
    "\n",
    "    return s_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataset(label=dataset_name,upload=True)\n",
    "def create_dataset():\n",
    "    df = load_dataset()\n",
    "    df = remove_columns(df)\n",
    "    df = rename_columns(df)\n",
    "    data  = dataset_imbalances(df)\n",
    "    X,Y,A_str = data['X'],data['Y'],data['A_str']\n",
    "    X_train, X_test, y_train, y_test, A_train, A_test = train_test_split(X, Y, A_str, test_size=0.35, stratify=Y)\n",
    "    data = resample_training_data(X_train, y_train, A_train)\n",
    "    X_train, y_train, A_train = data['X_train'],data['Y_train'],data['A_train']\n",
    "\n",
    "    A_test = add_new_column(sensitive_features=A_test)\n",
    "\n",
    "    return {\"x_train\":X_train,\"y_train\":y_train.to_numpy(),\"x_test\":X_test,\"y_test\":y_test.to_numpy(),\"sensitive_features\" : A_test}\n",
    "\n",
    "\n",
    "data_created = create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pureml.dataset.fetch(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pureml.decorators import model\n",
    "import pureml\n",
    "@model(label=model_name)\n",
    "def create_model():\n",
    "    data = pureml.dataset.fetch(dataset_name)\n",
    "    x_train = data['x_train']\n",
    "    y_train = data['y_train']\n",
    "    lgb_params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"learning_rate\": 0.412,\n",
    "    \"num_leaves\": 10,\n",
    "    \"max_depth\": 3,\n",
    "    \"random_state\": rand_seed,\n",
    "    \"n_jobs\": 1,}\n",
    "\n",
    "    pureml.log(params=lgb_params)\n",
    "    estimator = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocessing\", StandardScaler()),\n",
    "            (\"classifier\", lgb.LGBMClassifier(**lgb_params)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    estimator.fit(x_train, y_train)\n",
    "    return estimator\n",
    "\n",
    "model_lgb = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pureml\n",
    "\n",
    "pureml.predict.add(label=model_name,paths={'predict':'predict.py'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pureml\n",
    "\n",
    "pureml.predict.fetch(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pureml\n",
    "pureml.model.fetch(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pureml_evaluate.policy.policy_eval import eval\n",
    "\n",
    "result = eval(label_model = f\"{model_name}:v1\", label_dataset = dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
